import nltk
import re
import pandas as pd
import csv
import itertools
from collections import Counter

!pip install --upgrade spacy
!python3.7 -m spacy download ru_core_news_sm
import spacy

from nltk import Tree
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from string import punctuation
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger_ru')
nlp = spacy.load('ru_core_news_sm')

!git clone https://github.com/seriyps/ru_number_to_text

import ru_number_to_text
from ru_number_to_text.num2t4ru import num2text

import matplotlib.pyplot as plt
import numpy as np

!git clone https://github.com/sovaai/sova-tts-tps.git
!pip install loguru
!pip install unidecode

from tps import Handler

!pip3 install git+https://github.com/Desklop/StressRNN
!pip install stressrnn-0.2.*.whl
from stressrnn import StressRNN

!pip install epitran
import epitran

epi = epitran.Epitran('rus-Cyrl')  # Uyghur in Russian script

def my_num2text(tokens: list):
  n = 0
  for i, word in enumerate(tokens):
    if word.isnumeric():
      if len(word) == 1:
        tokens[i + n] = num2text(int(word))
      else:
        add = num2text(int(word)).split(' ')
        tokens = tokens[:i + n] + add + tokens[i + n + 1:]
        n += len(add) - 1

  return tokens
 
def tokenization(text: str):
  tokens = [w.lower() for w in text.split()]
  tokens = [re.sub('[^а-яё0-9\’\'\у́\-\+]', ' ', w, flags=re.IGNORECASE) for w in tokens if w != '']
  #tokens = [re.sub(r"\‑", '-', w) for w in tokens if w != '']
  tokens = [re.sub(r"\у́", 'у', w) for w in tokens if w != '']
  tokens = [re.sub(r"\’", '', w) for w in tokens if w != '']
  tokens = [re.sub(r"\'", '', w) for w in tokens if w != '']
  tokens = [re.sub(r'\s+', ' ', w) for w in tokens if w != '']
  tokens = [re.sub(r'\s$^\s', '', w) for w in tokens if w != '']
  n = 0
  for i, w in enumerate(tokens):
    if ' ' in w:
      tokens = tokens[:i + n] + w.split() + tokens[i + n + 1:]
      n += len(w.split()) - 1
  tokens = my_num2text(tokens)
  return tokens

def full_tokenization(text: str, a_text: str):
  tokens = tokenization(text)
  a_tokens = tokenization(a_text)

  n = 0
  for i, a_word in enumerate(a_tokens):
    while '-' in a_word:
      word = tokens[i + n]
      plus_counter = len([let for let in a_word if let == '+'])
      if plus_counter == 1:
        a_tokens = a_tokens[:i + n] + [a_word.replace('-', '')] + a_tokens[i + n + 1:]
        tokens = tokens[:i + n] + [word.replace('-', '')] + tokens[i + n + 1:]
        a_word = ''
      else:
        a_tokens = a_tokens[:i + n] + [a_word[:a_word.index('-')]] + [a_word[a_word.index('-') + 1:]] + a_tokens[i + n + 1:]
        tokens = tokens[:i + n] + [word[:word.index('-')]] + [word[word.index('-') + 1:]] + tokens[i + n + 1:]
        a_word = a_word[a_word.index('-') + 1:]
        n += 1
  
  return tokens, a_tokens
  
alphabet = alphabet.split(', ')

new_sor = sorted_al.split('\n')
sor_list = []
for x in new_sor:
  sor_list.append(x.split(', '))

sorted_phon = {}
for x in sor_list:
  for y in x:
    if '=' in y:
      index = y.index('=')
      sorted_phon[y[:index - 1]] = [y[index + 2:]] + x[1:]

paired_c_new = paired_c.split(', ')
paired = {}
for i, x in enumerate(paired_c_new):
  if '(' in x:
    paired[x[1:]] = paired_c_new[i + 1][:-1]

def get_key(d, value):
  for k, v in d.items():
    if v == value:
      return k

# creating a dictionary with all allophones
allophones = dict.fromkeys(alphabet)
for key in allophones.keys():
  if key in sorted_phon['total_v']:
    allophones[key] = {'phon': 'V', 'row': '', 'rise': '', 'round': ''}
    if key in sorted_phon['front_v']:  # row
      allophones[key]['row'] = 'front'
    elif key in sorted_phon['near_front_v']:
      allophones[key]['row'] = 'near front'
    elif key in sorted_phon['central_v']:
      allophones[key]['row'] = 'central'
    elif key in sorted_phon['near_back_v']:
      allophones[key]['row'] = 'near back'
    elif key in sorted_phon['back_v']:
      allophones[key]['row'] = 'back'
    
    if key in sorted_phon['close_v']:  # rise
      allophones[key]['rise'] = 'close'
    elif key in sorted_phon['near_close_v']:
      allophones[key]['rise'] = 'near close'
    elif key in sorted_phon['close_mid_v']:
      allophones[key]['rise'] = 'close mid'
    elif key in sorted_phon['mid_v']:
      allophones[key]['rise'] = 'mid'
    elif key in sorted_phon['open_mid_v']:
      allophones[key]['rise'] = 'open mid'
    elif key in sorted_phon['near_open_v']:
      allophones[key]['rise'] = 'near open'
    elif key in sorted_phon['open_v']:
      allophones[key]['rise'] = 'open'
    
    if key in sorted_phon['rounded_v']:  # round / velarize
      allophones[key]['round'] = 'round'
    elif key in sorted_phon['velarize_v']:
      allophones[key]['round'] = 'velarize'
    else:
      allophones[key]['round'] = 'not round and not velarize'

  elif key in sorted_phon['total_c']:
    allophones[key] = {'phon': 'C', 'place': '', 'manner': '', 'palatalization': '',
                       'voice': '', 'pair': None, 'hissing': None}
    if key in sorted_phon['bilabial_c']:  # place
      allophones[key]['place'] = 'labial, bilabial'
    elif key in sorted_phon['labiodental_c']:
      allophones[key]['place'] = 'labial, labiodental'
    elif key in sorted_phon['dental_c']:
      allophones[key]['place'] = 'lingual, dental'
    elif key in sorted_phon['palatinоdental_c']:
      allophones[key]['place'] = 'lingual, palatinоdental'
    elif key in sorted_phon['palatal_c']:
      allophones[key]['place'] = 'lingual, palatal'
    elif key in sorted_phon['velar_c']:
      allophones[key]['place'] = 'lingual, velar'
    elif key in sorted_phon['glottal_c']:
      allophones[key]['place'] = 'glottal'
    
    if key in sorted_phon['explosive_c']:  # manner
      allophones[key]['manner'] = 'obstruent, explosive'
    elif key in sorted_phon['affricate_c']:
      allophones[key]['manner'] = 'obstruent, affricate'
    elif key in sorted_phon['fricative_c']:
      allophones[key]['manner'] = 'obstruent, fricative'
    elif key in sorted_phon['nasal_c']:
      allophones[key]['manner'] = 'sonorant, nasal'
    elif key in sorted_phon['lateral_c']:
      allophones[key]['manner'] = 'sonorant, lateral'
    elif key in sorted_phon['vibrant_c']:
      allophones[key]['manner'] = 'sonorant, vibrant'
    
    if key in sorted_phon['hard_c']:  # hard / soft
      allophones[key]['palatalization'] = 'hard'
    elif key in sorted_phon['always_hard_c']:
      allophones[key]['palatalization'] = 'ahard'
    elif key in sorted_phon['soft_c']:
      allophones[key]['palatalization'] = 'soft'
    elif key in sorted_phon['always_soft_c']:
      allophones[key]['palatalization'] = 'asoft'
    
    if key in sorted_phon['voiced_c']:  # voice / silent
      allophones[key]['voice'] = 'voiced'
      if key in paired.keys():
        allophones[key]['pair'] = paired[key]
    elif key in sorted_phon['voiceless_c']:
      allophones[key]['voice'] = 'voiceless'
      if key in paired.values():
        allophones[key]['pair'] = get_key(paired, key)

    if key in sorted_phon['ship_c']:  # hissing sounds
      allophones[key]['hissing'] = 'hissing'

allophones.update({'+': {'phon': 'symb'}})
allophones.update({'-': {'phon': 'symb'}})

starterpack = ['a', 'b', 'bʲ', 'v', 'vʲ', 'ɡ', 'ɡʲ', 'd', 'dʲ', 'e', 'ʒ', 'z',
               'zʲ', 'i', 'j', 'k', 'kʲ', 'l', 'lʲ', 'm', 'mʲ', 'n', 'nʲ', 'o',
               'p', 'pʲ', 'r', 'rʲ', 's', 'sʲ', 't', 'tʲ', 'u', 'f', 'fʲ', 'x',
               'xʲ', 't͡s', 't͡ɕ', 'ʂ', 'ɕː', 'ɨ', 'd͡ʒ']  # epi phonemes 

rus_v = ['а', 'е', 'ё', 'и', 'о', 'у', 'э', 'ю', 'я', 'ы']  # russian vowels

def to_nltk_tree(node):
  if node.n_lefts + node.n_rights > 0:
    return Tree(node, [to_nltk_tree(child) for child in node.children])
  else:
    return node

def make_dependency_tree(text):
  doc = nlp(text)
  for sent in doc.sents:
    dependency_tree = to_nltk_tree(sent.root)
    return dependency_tree
 
def clitics(dep, text:list, a_text:list, n=0):
  functors_pos = {'CCONJ', 'PART', 'ADP'}
  adverb_adp = ['после', 'кругом', 'мимо', 'около', 'вокруг', 'напротив', 'поперёк']

  if len(str(dep).split(' ')) > 1:
    for token in dep:
      if isinstance(token, nltk.tree.Tree):
        res = clitics(token, text, a_text, n)
        a_text = res[0]
        n = res[1]
      else:
        if token.pos_ in functors_pos and token.text not in adverb_adp:
          if '+' in a_text[token.i + n]:
            clitic = a_text[token.i + n].replace('+', '')
          else:
            clitic = a_text[token.i + n]
          if token.i < len(text) - 1:
            if text[token.i + n + 1] in str(dep) and text[token.i + n + 1][0] not in 'еёюяи' :  # proclitics
              a_text = a_text[:token.i + n] + [clitic + a_text[token.i + n + 1]] + a_text[token.i + n + 2:]
              n -=  1
          elif token.i > 0:
            if text[token.i + n - 1] in str(dep): # enclitics
              a_text = a_text[:token.i + n - 1] + [a_text[token.i + n - 1] + clitic] + a_text[token.i + n + 1:]
              n -= 1
  return a_text, n

def accent_replacing(text: list):
  new_text = []
  a_text = text
  for i, word in enumerate(a_text):
    new_word = ''
    if '+' in word:
      new_word = word[:word.index('+')] + word[word.index('+') + 1: word.index('+') + 2] + '+' + word[word.index('+') + 2:]
    else:
      new_word = stress_rnn.put_stress(word, stress_symbol='+', accuracy_threshold=0.75, replace_similar_symbols=True)
    if '+' in new_word and len(new_word) > 2:
      preavi = []  # pre acented vowel indexes
      for i, fon in enumerate(new_word[:new_word.index('+') - 1]):
        if fon in rus_v:
          preavi.append(i)
      if preavi:
        new_word = new_word[:preavi[-1] + 1] + '-' + new_word[preavi[-1] + 1:]
    new_text += [new_word]
  return new_text
  
def transcribe(word: str):
  if word == 'сего+дня':
    word = 'сево+дня'
  elif word == 'его+':
    word = 'ево+'
  elif word[-4:] == 'о+го':
    word = word[:-4] + 'о+во'
  elif word[-3:] == 'ого':
    word = word[:-3] + 'ово'
  translited_word = epi.transliterate(word)
  res = []
  del_idx = []
  if 't͡ɕʲ' in translited_word:
    translited_word = translited_word.replace('t͡ɕʲ', 't͡ɕ')
  if 'ʂʲː' in translited_word:
    translited_word = translited_word.replace('ʂʲː', 'ʂ')
  if 'ɕːʲ' in translited_word:
    translited_word = translited_word.replace('ɕːʲ', 'ɕː')
  for i, symb in enumerate(translited_word):
    if symb != '+' and symb != '-':
      n = 4
      if i != len(translited_word) - 1:
        while translited_word[i:i + n] not in starterpack and n > 0:
          n -= 1
        if n > 1:
          for n_i in range(1, n):
            del_idx.append(i + n_i)
      res.append(translited_word[i:i + n])
    else:
      res.append(symb)
  res[:] = [x for i, x in enumerate(res) if i not in del_idx]
  return res
 
exeptions_jot = 'кафе отель купе'
nlp_ex_jot = nlp(exeptions_jot)
ex_jot_lemmas = []
for token in nlp_ex_jot:
  ex_jot_lemmas.append(token.lemma_)
  
def jot_v(orig_word: str, word: list):
  nlp_word = nlp(orig_word)
  word_lemma = nlp_word[0].lemma_
  n = 0
  if word[0] == 'j' and orig_word[0] != 'й':
    n += 1
  if 'd͡ʒ' in word:
    n -= 1
  for i, let in enumerate(orig_word):
    if let == 'ь' or let == 'ъ' or let == '-' or let == '+':
      n -= 1
    elif i != len(word) - 1:
      if word[i + n] == '+' or word[i + n] == '-':
        n += 1
    if let == 'е' or let == 'ё' or let == 'ю' or let == 'я':
      if i != 0:
        if orig_word[i - 1] == 'ь' or orig_word[i - 1] == 'ъ':
          if word[i + n] != 'j':
            word = word[:i + n] + ['j'] + word[i + n:]
            n += 1
          else:
            n += 1
        elif orig_word[i - 1] in rus_v:
          if word[i + n - 1] != 'j':
            word = word[:i + n] + ['j'] + word[i + n:]
            n += 1
          else:
            n += 1
        elif allophones[word[i + n - 1]]['phon'] == 'C'\
        and 'ʲ' not in word[i + n - 1] and word_lemma not in ex_jot_lemmas\
        and word [i + n] != 'э':
          if 'a' not in allophones[word[i + n - 1]]['palatalization'][0]:
            word[i + n - 1] = word[i + n - 1] + 'ʲ'
        elif word_lemma in ex_jot_lemmas and 'ʲ' in word[i + n - 1]:
          word[i + n - 1] = word[i + n - 1][:-1]
      elif i < len(orig_word) - 2:
        if orig_word[i + 2] == '+':
          if word[i + n - 1] != 'j':
            word = word[:i + n] + ['j'] + word[i + n:]
            n += 1
          elif i + n - 1 != 0:
            n += 1
    elif let == 'и' and i != 0:
      if orig_word[i - 1] == 'ь':
        if word[i + n - 1] != 'j':
          word = word[:i + n] + ['j'] + word[i + n:]
          n += 1
        else:
          n += 1
      elif allophones[word[i + n - 1]]['phon'] == 'C'\
      and 'ʲ' not in word[i + n - 1]:
        if allophones[word[i + n - 1]]['palatalization'] != 'ahard'\
        and allophones[word[i + n - 1]]['palatalization'] != 'asoft':
          word[i + n - 1] = word[i + n - 1] + 'ʲ'
  return word

def nasal_m(word: list):
  for i, fon in enumerate(word[:-1]):
    if fon == 'm':
      if allophones[word[i + 1]]['phon'] == 'C':
        if allophones[word[i + 1]]['place'] == 'labial, labiodental':
          word[i] = 'ɱ'
    elif fon == 'mʲ':
      if allophones[word[i + 1]]['phon'] == 'C':
        if allophones[word[i + 1]]['place'] == 'labial, labiodental':
          word[i] = 'ɱʲ'
  return word

def silent_r(word: list):
  for i, fon in enumerate(word):
    if fon == 'r':
      if i == len(word) - 1:
        word[i] = 'r̥'
      elif allophones[word[i + 1]]['phon'] == 'C':
        if allophones[word[i + 1]]['voice'] == 'voiceless':
          word[i] = 'r̥'
    elif fon =='rʲ':
      if i == len(word) - 1:
        word[i] = 'r̥ʲ'
  return word

def vosed_ts(word: list):
  for i, fon in enumerate(word[:-1]):
    if allophones[word[i + 1]]['phon'] == 'C':
      if fon == 't͡s' and allophones[word[i + 1]]['voice'] == 'voiced':
        word[i] = 'd̻͡z̪'
  return word

fricative_g = 'ага ого господь господи'
nlp_fric_g = nlp(fricative_g)
fricg_lemmas = []
for token in nlp_fric_g:
  fricg_lemmas.append(token.lemma_)

def fricative_g(orig_word: str, word: list):
  nlp_word = nlp(orig_word)
  word_lemma = nlp_word[0].lemma_
  if word_lemma in fricg_lemmas:
    for i, fon in enumerate(word):
      if fon == 'ɡ':
        word[i] = 'γ'
  return word
  
exeptions_tsa = 'заботься отметься'
nlp_ex_tsa = nlp(exeptions_tsa)
ex_tsa_lemmas = []
for token in nlp_ex_tsa:
  ex_tsa_lemmas.append(token.lemma_)
  
def ending_tsa(orig_word: str, word: list):
  nlp_word = nlp(orig_word)
  word_lemma = nlp_word[0].lemma_
  if word_lemma not in ex_tsa_lemmas:
    if word[-3:] == ['tʲ', 'sʲ', 'a'] or word[-3:] == ['t', 'sʲ', 'a']:
      word = word[:-3] + ['t͡s', 'a']
  return word

exeptions_palatalize = 'сосиски злить после'
nlp_ex_pal = nlp(exeptions_palatalize)
ex_pal_lemmas = []
for token in nlp_ex_pal:
  ex_pal_lemmas.append(token.lemma_)

def palatalize(orig_word: str, word: list):
  nlp_word = nlp(orig_word)
  word_lemma = nlp_word[0].lemma_
  if word_lemma not in ex_pal_lemmas:
    for i, fon in enumerate(word[:-1]):
      if ['i', '+', 'z', 'm'] not in word and 'ʲ' not in word[i]:
        if allophones[fon]['phon'] == 'C'\
        and allophones[word[i + 1]]['phon'] == 'C':
          if allophones[word[i + 1]]['palatalization'] == 'soft'\
          and 'lab' not in allophones[word[i + 1]]['place']\
          and allophones[word[i]]['palatalization'][0] != 'a':
            word[i] = word[i] + 'ʲ'
  return word

def vocalization(orig_word:str, word: list):
  if orig_word == 'бог':
    word[-1] = 'x'
  else:
    if allophones[word[-1]]['phon'] == 'C':
      if allophones[word[-1]]['voice'] == 'voiced'\
      and allophones[word[-1]]['pair'] != None:
        word[-1] = allophones[word[-1]]['pair']
    for i in range(len(word) - 1):
      if allophones[word[i + 1]]['phon'] == 'C'\
      and allophones[word[i]]['phon'] == 'C':
        if allophones[word[i + 1]]['voice'] == 'voiced' and word[i + 1] != 'j'\
        and 'son' not in allophones[word[i + 1]]['manner']\
        and 'v' not in word[i + 1] and allophones[word[i]]['pair'] != None:
          word[i] = allophones[word[i]]['pair']
  return word

def long_hissing(orig_word: str, word: list):
  snowball = SnowballStemmer('russian')
  stem = snowball.stem(orig_word)
  for i, fon in enumerate(word):
    if i < len(word) - 2:
      if fon == 's' and word[i + 1] == 'ʂ'\
      or fon == 'z' and word[i + 1] == 'ʂ':
        word.pop(i + 1)
        word[i] = 'ʂː'
      elif fon == 's' and word[i + 1] == 'ʒ':
        word.pop(i + 1)
        word[i] = 'ʑː'
      elif fon == 'z' and word[i + 1] == 'ʒ'\
      or fon == 'ʒ' and word[i + 1] == 'ʒ':
        """if 'зж' in stem or 'жж' in stem:
          word.pop(i + 1)
          word[i] = 'ʑːʲ'
        else:"""
        word.pop(i + 1)
        word[i] = 'ʑː'
      elif fon == 's' and word[i + 1] == 't͡ɕʲ':
        word.pop(i + 1)
        word[i] = 'ɕː'
      elif fon == 'z' and word[i + 1] == 't͡ɕʲ':
        if stem[-3:] == 'чик' or stem[-3:] == 'чиц':
          word.pop(i + 1)
          word[i] = 'ɕː'
      elif fon == 't' and word[i + 1] == 't͡ɕʲ'\
      or fon == 'd' and word[i + 1] == 't͡ɕʲ':
        if stem[-3:] == 'чик' or stem[-3:] == 'чиц':
          word.pop(i + 1)
          word[i] = 't͡ɕːʲ'
  return word
  
exeptions_long_c = 'россия одиннадцать пятьдесят шестьдесят колммуналка грипп'
nlp_ex_long_c = nlp(exeptions_long_c)
ex_long_c_lemmas = []
for token in nlp_ex_long_c:
  ex_long_c_lemmas.append(token.lemma_)

def short_c(word_lemma: str, word: list, c_index=None):
  if word_lemma in ex_long_c_lemmas:
    for i, fon in enumerate(word):
      if i < len(word) - 2:
        if fon == word[i + 1]:
          word = word[:i] + word[i + 1:]
  elif c_index:
    word = word[:c_index] + word[c_index + 1:]
  return word

def long_c(orig_word: str, word: list):
  nlp_word = nlp(orig_word)
  word_lemma = nlp_word[0].lemma_
  long_fons = 'bpfkstrlmngdz'
  n = 0
  if word_lemma not in ex_long_c_lemmas:
    for i, fon in enumerate(word):
      if i < len(word) - 2:
        if fon == word[i + n + 1] and allophones[fon]['phon'] == 'C':
          if fon in long_fons.split():
            word = word[:i + n] + [fon + 'ː'] + word[i + 2:]
            n -= 1
          else:
            word = short_c(orig_word, word, i)
  else:
    word = short_c(word_lemma, word)
  return word
  
def unpron_c(orig_word: str, word: list):
  for i in range(len(word[:-2])):
    if word[i:i + 3] == ['s', 't', 'n'] or word[i:i + 3] == ['s', 't', 'l']\
    or word[i:i + 3] == ['s', 't', 'lʲ'] or word[i:i + 3] == ['z', 'd', 'n']\
    or word[i:i + 3] == ['z', 'd', 'nʲ'] or word[i:i + 3] == ['r', 'd', 'n']\
    or word[i:i + 4] == ['n', 't', 's', 'k'] or word[i:i + 4] == ['n', 't', 's', 'kʲ']\
    or word[i:i + 4] == ['n', 'd', 's', 'k'] or word[i:i + 4] == ['n', 'd', 's', 'kʲ']\
    or word[i:i + 5] == ['l', 'v', 's', 't', 'v']:
      word = word[:i + 1] + word[i + 2:]
    elif word[i:i + 3] == ['l', 'n', 't͡s'] or word[i:i + 2] == ['d', 't͡s']\
    or word[i:i + 4] == ['v', 's', 't', 'v']:
      word = word[:i] + word[i + 1:]
  return word

def vowel_a(word: list):
  for i, fon in enumerate(word):
    if fon == 'a':
      if i != len(word) - 1 and i != 0:
        if word[i + 1] == '+':  # ударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ɐ.'
            elif 'soft' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'æ'
            elif i != len(word) - 2:
              if 'hard' in allophones[word[i - 1]]['palatalization']\
              and word[i + 2] == 'l':
                word[i] = 'ɑ'
          else:
            word[i] = 'æ'
        elif word[i + 1] == '-':  # первый предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ᵻ'
            elif 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ɐ'
          else:
            word[i] = 'ɪ'
        else:  # заударные/второй предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing'\
            or 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ə'
          else:
            word[i] = 'ɪ.'
      elif i == len(word) - 1:   # заударные (last)
        if allophones[word[i - 1]]['phon'] == 'C':
          if allophones[word[i - 1]]['hissing'] == 'hissing':
            word[i] = 'ə'
          elif 'hard' in allophones[word[i - 1]]['palatalization']:
            word[i] = 'ʌ'
        else:
          word[i] = 'æ.'
      else:
        if word[i + 1] == '-':  # первый предударный (first)
          word[i] = 'ɐ'
        elif word[i + 1] != '+':  # заударные/второй предударный (first)
          word[i] = 'ə'
  return word
  
def vowel_o(word: list):
  for i, fon in enumerate(word):
    if fon == 'o':
      if i != len(word) - 1 and i != 0:
        if word[i + 1] == '+':  # ударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ɐ.'
            elif 'soft' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ɵ'
          else:
            word[i] = 'ɵ'
        elif word[i + 1] == '-':  # первый предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ᵻ'
            elif 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ɐ'
          else:
            word[i] = 'ɪ'
        else:  # заударные/второй предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing'\
            or 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ə'
          else:
            word[i] = 'ɪ.'
      elif i == len(word) - 1:   # заударные (last)
        if allophones[word[i - 1]]['phon'] == 'C':
          if allophones[word[i - 1]]['hissing'] == 'hissing':
            word[i] = 'ə'
          elif 'hard' in allophones[word[i - 1]]['palatalization']:
            word[i] = 'ʌ'
        else:
          word[i] = 'æ.'
      else:
        if word[i + 1] == '-':  # первый предударный (first)
          word[i] = 'ɐ'
        elif word[i + 1] != '+':  # заударные/второй предударный (first)
          word[i] = 'ə'
  return word
  
def vowel_e(word: list):
  for i, fon in enumerate(word):
    if fon == 'e':
      if i < len(word) - 1 and i != 0:
        if word[i + 1] == '+' and allophones[word[i - 1]]['phon'] == 'C':  # ударный (not last, not first)
          if allophones[word[i - 1]]['hissing'] == 'hissing':
            word[i] = 'ᵻ'
          elif 'hard' in allophones[word[i - 1]]['palatalization']:
            word[i] = 'ɛ'
        elif word[i + 1] == '-':  # первый предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ə'
            elif 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ᵻ'
          else:
            word[i] = 'ɪ'
        else:  # заударные/второй предударный (not last, not first)
          if allophones[word[i - 1]]['phon'] == 'C':
            if allophones[word[i - 1]]['hissing'] == 'hissing':
              word[i] = 'ə'
            elif 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ᵻ'
          else:
            word[i] = 'ɪ.'
      elif i == len(word) - 1:   # заударные (last)
        if allophones[word[i - 1]]['phon'] == 'C':
          if allophones[word[i - 1]]['hissing'] == 'hissing':
            word[i] = 'ə'
          elif 'hard' in allophones[word[i - 1]]['palatalization']:
            word[i] = 'ᵻ'
        else:
          word[i] = 'æ.'
      else:
        if word[i + 1] == '+':  # ударный (first)
          word[i] = 'ɛ'
        elif word[i + 1] == '-':  # первый предударный (first)
          word[i] = 'ᵻ'
        else:  # заударные/второй предударный (first)
          word[i] = 'ɪ.'
  return word
  
def vowel_u(word: list):
  for i, fon in enumerate(word):
    if fon == 'u':
      if i != len(word) - 1:
        if word[i + 1] == '+':  # ударный
          if allophones[word[i - 1]]['phon'] == 'C':
            if 'soft' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ʉ'
        else:  # первый/второй предударный/заударные не посл.
          if allophones[word[i - 1]]['phon'] == 'C':
            if 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ʊ'
          else:
            word[i] = 'ᵿ'
      else:  # первый/второй предударный/заударные посл.
        if allophones[word[i - 1]]['phon'] == 'C':
            if 'hard' in allophones[word[i - 1]]['palatalization']:
              word[i] = 'ʊ'
        else:
          word[i] = 'ᵿ'
  return word
  
def vowel_i(word: list):
  for i, fon in enumerate(word):
    if fon == 'i' and allophones[word[i - 1]]['phon'] == 'C':
      if i == 0:  # и первый
        if word[i + 1] != '+':
          word[i] = 'ɪ'
      elif i == len(word) - 1:  # и последний (не может быть ударным)
        if allophones[word[i - 1]]['hissing'] == 'hissing':
          word[i] = 'ɨ'
        else:
          word[i] = 'ɪ'
      else:
        if allophones[word[i - 1]]['hissing'] == 'hissing':
          word[i] = 'ɨ'
        elif word[i + 1] != '+':
          word[i] = 'ɪ'
  return word
  
def vowel_ii(word: list):
  for i, fon in enumerate(word):
    if fon == 'ɨ' and allophones[word[i - 1]]['phon'] == 'C':
      if i < len(word) - 1:
        if word[i + 1] == '+':  # ударный
          if len(word) > 4:
            if word[i - 1] == 'l' and allophones[word[i - 2]]['phon'] == 'C':
              if 'lab' in allophones[word[i - 2]]['place']:
                word[i] = 'ɯ̟ɨ̟'
          if i < len(word) - 2:
            if allophones[word[i + 2]]['phon'] == 'C':
              if allophones[word[i - 1]]['place'] == 'lingual, dental'\
              and allophones[word[i + 2]]['place'] == 'lingual, velar'\
              or allophones[word[i - 1]]['place'] == 'lingual, palatinоdental'\
              and allophones[word[i + 2]]['place'] == 'lingual, velar':
                word[i] = 'ɨ̟'
        else:  # предударный / заунарный (not last)
          if allophones[word[i - 1]]['hissing'] == 'hissing':
            word[i] = 'ə'
          else:
            word[i] = 'ᵻ'
      else:  # заунарный (last)
        if allophones[word[i - 1]]['hissing'] == 'hissing':
          word[i] = 'ə'
        else:
          word[i] = 'ᵻ'
  return word
  
def labia_velar(word: list):
  for i, fon in enumerate(word):
    if allophones[fon]['phon'] == 'V' and i != 0:
      if allophones[word[i - 1]]['phon'] == 'C':
        if allophones[fon]['round'] == 'round' and 'ʷ' not in word[i - 1] and i != 0:
          word[i - 1] = word[i - 1] + 'ʷ'
          if i != len(word) - 2:
            word = labia_velar(word)
            break
        elif allophones[fon]['round'] == 'velarize' and 'soft' not in allophones[word[i - 1]]['palatalization'] and 'ˠ' not in word[i - 1]:
          word[i - 1] = word[i - 1] + 'ˠ'
          if i != len(word) - 2:
            word = labia_velar(word)
            break
  return word
  
def full_transcribe(ent_text: str, ent_a_text=None):
  if not ent_a_text:
    ent_a_text = ent_text
  texts = full_tokenization(ent_text, ent_a_text)
  dep = make_dependency_tree(' '.join(texts[0]))
  phrasal_words = clitics(dep, texts[0], accent_replacing(texts[1]))[0]
  trans_tokens = []
  for word in phrasal_words:  
    res = transcribe(word)
    res = jot_v(word, res)
    res = nasal_m(res)
    res = silent_r(res)
    res = vosed_ts(res)
    res = fricative_g(word, res)
    res = ending_tsa(word, res)
    res = palatalize(word, res)
    res = vocalization(word, res)
    res = long_hissing(word, res)
    res = long_c(word, res)
    res = unpron_c(word, res)
    res = vowel_a(res)
    res = vowel_o(res)
    res = vowel_e(res)
    res = vowel_u(res)
    res = vowel_i(res)
    res = vowel_ii(res)
    res = labia_velar(res)
    trans_tokens += res
  return trans_tokens
